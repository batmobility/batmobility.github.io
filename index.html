<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-2GM44LM2Q7"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-2GM44LM2Q7');
  </script>

   <meta charset="utf-8">
  <meta name="description" content="BatMobility: Towards Flying Without Seeing for Autonomous Drones">
   <meta http-equiv="X-UA-Compatible" content="IE=edge">
   <title>BatMobility: Towards Flying Without Seeing for Autonomous Drones</title>
  <link href="static/css/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <script defer src="./static/js/fontawesome.all.min.js"></script>

  <style>
      .header {
        width: auto;
        max-width: auto;
        padding-top: 4rem;
        padding-bottom: 2rem;
        margin-bottom: 2rem;
        background-color: rgba(250, 250, 250)
      }

      a:link,a:visited
      {
        color: #0071bc;
        text-decoration: none;
      }

      a:hover {
        color: #208799;
      }

      hr {
        border: 10;
        height: 1px;
        background-image: linear-gradient(to right, rgba(0, 113, 188, 0.2), rgba(0, 0, 0, 0.1), rgba(0, 113, 188, 0.2));
      }

      .gap-30 {height:30px;}
      .gap-20 {height:20px;}
      .gap-10 {height:10px;}
      .gap-5 {height:5px;}

      .no-gutters {
        margin-right: 0;
        margin-left: 0;
      }

      .btn {
        margin-left: 0.2rem;
        margin-right: 0.2rem;
	  }

    </style>
</head>

<div class="header">
	<div class="container">
        <center><h1>BatMobility: Towards Flying Without <br> Seeing for Autonomous Drones</h1></center>
		<div class="gap-10"></div>
		<!--------------------- Author Names --------------------->
		<center>
			<a href="https://sie2.github.io/" target="_blank" style="font-size:20px">Emerson Sie</a>,
			<a href="zikunliu6.github.io" target="_blank" style="font-size:20px">Zikun Liu</a>,
			<a href="deepakv.web.illinois.edu" target="_blank" style="font-size:20px">Deepak Vasisht</a>
		</center>

		<div class="gap-10"></div>

		<center>
            University of Illinois Urbana-Champaign
		</center>

		<div class="gap-20"></div>

        <center>
          <img src='resources/artifacts_available_v1_1.png' width=100px>
          <img src='resources/artifacts_evaluated_reusable_v1_1.png' width=100px>
          <img src='resources/results_reproduced_v1_1.png' width=100px>
        </center>

		<div class="gap-20"></div>

		<center>
			<div class="btn-group" role="group">

				<a href="https://arxiv.org/pdf/2307.11518">
					<button type="button" class="btn btn-dark">
						<span class="icon"><i class="fas fa-file-pdf"></i> Paper</span>
					</button>
				</a>

				<a href="https://dl.acm.org/doi/10.1145/3570361.3592532">
					<button type="button" class="btn btn-dark">
                        <span class="icon"><i class="ai ai-acmdl"></i> ACM DL</span>
					</button>
				</a>

				<a href="https://arxiv.org/abs/2307.11518">
					<button type="button" class="btn btn-dark">
                        <span class="icon"><i class="ai ai-arxiv"></i> arXiv</span>
					</button>
				</a>

				<a href="https://github.com/ConnectedSystemsLab/batmobility_ae">
					<button type="button" class="btn btn-dark">
						<span class="icon"><i class="fab fa-github"></i> Code</span>
					</button>
				</a>

				<a href="https://zenodo.org/record/8312500">
					<button type="button" class="btn btn-dark">
                        <span class="icon"><i class="far fa-images"></i> Data</span>
					</button>
				</a>

				<a href="https://sigmobile.org/mobicom/2023/media/presentations/SieBatMobility.pdf">
					<button type="button" class="btn btn-dark">
                        <span class="icon"><i class="fa fa-list"></i> Slides</span>
					</button>
				</a>

			</div>
		</center>

	</div>
</div>

<div class="container">

    <center>
          <video autoplay muted loop controls width="600px" 
              src="./resources/batmobility_flying-opt.webm">
          </video>
    </center>

    <center>
        <p style="width:90%; text-align: center; white-space: normal;">
        <b>TL;DR: Doppler shift enables autonomous navigation in challenging environments lacking visual or geometric features.</b>
    </center>

    <!--------------------- abstract --------------------->
    <!-- <div class="gap-10"></div> -->
    <h2 style="text-align: center"> Abstract </h2>
    <!-- <div class="gap-10"></div> -->
    <center>
        <p style="width:90%; text-align: justify; white-space: normal;"> 
            Unmanned aerial vehicles (UAVs) rely on optical sensors such as cameras and lidar for autonomous operation. However, optical sensors fail under bad lighting, are occluded by debris and adverse weather conditions, struggle in featureless environments, and easily miss transparent surfaces and thin obstacles. In this paper, we question the extent to which optical sensors are sufficient or even necessary for full UAV autonomy. Specifically, we ask: can UAVs autonomously fly without seeing? We present BatMobility, a lightweight mmWave radar-only perception system for autonomous UAVs that completely eliminates the need for any optical sensors. BatMobility enables vision-free autonomy through two key functionalities â€“ radio flow estimation (a novel FMCW radar-based alternative for optical flow based on surface-parallel doppler shift) and radar-based collision avoidance. We build BatMobility using inexpensive commodity sensors and deploy it as a real-time system on a small off-the-shelf quadcopter, showing its compatibility with existing flight controllers. Surprisingly, our evaluation shows that BatMobility achieves comparable or better performance than commercial-grade optical sensors across a wide range of scenarios. 
</p>
    </center>

    <hr>

    <h2 style="text-align: center"> Surface-Parallel Doppler Shift </h2>

    <center><p style="width:90%; text-align: justify; white-space: normal;">
        <strong>How can we stabilize a drone using only a downward facing radar?</strong> Although obtaining altitude is straightforward, ground-parallel motion is challenging. Our key insight is that at mmWave frequencies, most ground surfaces appear diffuse to radar. This means ground-parallel motion induces unique patterns in the doppler-angle plane. We can make such patterns apparent even on very low resolution antenna arrays by extending the doppler axis.
    </p></center>

    <div class="container">
      <div class="row">
        <div class="col-md-4 row center-row">
          <video autoplay loop muted playsinline src="./resources/spd.mp4" width=100%></video>
        </div>
        <div class="col-md-8">
          <div class="row">
            <div class="col-md-12">
                <strong>Velocity is correlated with the amplitude.</strong>   

               <center>
                   <video autoplay loop muted playsinline src="./resources/anim2-opt.webm" width=100%></video>
               </center>
            </div>
          </div>
          <div class="row">
            <div class="col-md-12">
                <strong>Direction can be found using 2D antenna array.</strong>   

               <center>
                   <video autoplay loop muted playsinline src="./resources/anim3-opt.webm" width=100%></video>
               </center>
            </div>
          </div>
        </div>
      </div>
    </div>

    <hr>

    <div class="gap-10"></div>
    <h2 style="text-align: center"> Doppler Flow </h2>
    <div class="gap-10"></div>

    <center><p style="width:90%; text-align: justify; white-space: normal;">
        The previous simulated toy examples assume a perfectly diffuse surface. However, doppler-angle heatmaps generally appear different under various real world conditions due to specularity, multipath, noise, etc. We collect data on various real world surfaces and train a lightweight CNN to regress velocity from imperfect doppler-angle heatmaps. We also convert these to angular flow values for plug-and-play compatibility with existing flight controllers.
    </p></center>

    <center>
        <img style="width: 100%;" src="./resources/flow_model.jpg">
    </center>

    <div class="gap-10"></div>


    <div class="row no-gutters">
        <div class="col">
            <center><b>Rough Surface (Grass)</b></center>
            <video autoplay loop muted playsinline src="./resources/grass1-opt.webm" width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
        <div class="col">
            <center><b>Smooth Surface (Concrete)</b></center>
            <video autoplay loop muted playsinline src="./resources/wall1-opt.webm"  width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
    </div>

    <hr>

    <div class="gap-10"></div>
    <h2 style="text-align: center"> Position Hold </h2>
    <div class="gap-10"></div>

    <center><p style="width:90%; text-align: justify; white-space: normal;">
        We compare loitering behavior of a UAV using (a) a commercial optical flow sensor and (b) BatMobility. In the left, we can see that the UAV is unable to hold its position in featureless or dark environments. In the right, BatMobility uses surface-parallel doppler shift to maintain stability in spite of the lack of visual or geometric ground features.
    </p></center>

    <div class="row no-gutters">
        <div class="col">
            <center><b>Optical Flow</b></center>
            <video autoplay loop muted playsinline src="./resources/optflow_tless3-opt.webm" width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
        <div class="col">
            <center><b>Doppler Flow</b></center>
            <video autoplay loop muted playsinline src="./resources/batmobility_tless2-opt.webm" width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
    </div>

    <div class="row no-gutters">
        <div class="col">
            <center><b>Optical Flow</b></center>
            <video autoplay loop muted playsinline src="./resources/optflow_dark2-opt.webm" width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
        <div class="col">
            <center><b>Doppler Flow</b></center>
            <video autoplay loop muted playsinline src="./resources/batmobility_dark3-opt.webm" width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
    </div>

    <hr>

    <div class="gap-10"></div>
    <h2 style="text-align: center"> Velocity Control </h2>
    <div class="gap-10"></div>

    <center><p style="width:90%; text-align: justify; white-space: normal;">
        BatMobility enables feedback-based velocity control in harsh environments (such as in the dark). This enables key action primitives (i.e. move forward, move left, turn right, stop) for vision-free navigation in unstructured environments.
    </p></center>

    <div class="row no-gutters">
        <div class="col">
            <video autoplay loop muted playsinline src="./resources/batmobility_square1-opt.webm" width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
        <div class="col">
            <video autoplay loop muted playsinline src="./resources/batmobility_square2-opt.webm" width=97%
                style="border-radius:10px; border:1px solid black"></video>
        </div>
    </div>

    <hr>

    <h2 style="text-align: center"> Related Work </h2>

    <center>
        This work is part of our series of research on radar-based perception for robots.<br/><br/>
      <table width="100%">
        <tr>
          <td width="100%">
          <font size = 4>
            <div style="float:left;margin-right:30px;">
            <video autoplay loop muted src="resources/radarize.mp4" width="360"></video>
            </div>
            <b>Radarize: Enhancing Radar SLAM with Generalizable Doppler-Based Odometry</b><br/>
            Emerson Sie, Xinyu Wu, Heyu Guo, Deepak Vasisht<br/>
            MobiSys 2024 <br/> <br/>
            <a href="https://arxiv.org/pdf/2311.11260">PDF</a> | 
            <a href="https://radarize.github.io/">Project Page</a> 
          </font>

        </tr>
      </table>
    </center> 

    <hr>

    <h2 style="text-align: center"> Bibtex </h2>
	<pre style="background-color: #f4f4f4;">

@inproceedings{sie2023batmobility,
  author    = {Sie, Emerson and Liu, Zikun and Vasisht, Deepak},
  title     = {BatMobility: Towards Flying Without Seeing for Autonomous Drones},
  booktitle = {ACM International Conference on Mobile Computing (MobiCom)},
  year      = {2023},
  doi       = {https://doi.org/10.1145/3570361.3592532},
}
    </pre>

	<hr>

	<b><span style="font-size:22px">Acknowledgements:</span></b><br>

          We thank the reviewers and our anonymous shepherd for their insightful comments and suggestions on improving this paper. This work was supported in part by NSF RINGS Award 2148583. This work was carried out in part in the Intelligent Robotics Laboratory, University of Illinois Urbana-Champaign. We thank John M. Hart for help regarding the flying arena. We thank Shahab Nikkhoo for his guidance and suggestions. We thank Kris Hauser for letting us use his 3D printer. We are grateful to Jayanth Shenoy, Bill Tao, Maleeha Masood, Ishani Janveja, and Om Chabra for their feedback on initial drafts.

	<p style="text-align: right"><a href="https://github.com/HaozhiQi/haozhiqi.github.io/tree/master/hora" style="font-size:12px;">Template for this Website</a></p>


    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="res/js/bootstrap.min.js"></script>

</div>
</html>
